{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregating Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600px\"\n",
       "            src=\"https://projector-video-pdf-converter.datacamp.com/22066/chapter2.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x22dae87dfd0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "# Display PDF with responsive width and height\n",
    "IFrame(\"https://projector-video-pdf-converter.datacamp.com/22066/chapter2.pdf\", width=\"100%\", height=\"600px\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Summary Statistics\n",
    "### (Theory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a). Summarizing numerical data\n",
    "- .median() \n",
    "- .mode()\n",
    "- .min() \n",
    "- .max()\n",
    "- .var()  \n",
    "- .std()\n",
    "- .sum()\n",
    "- .quantile()\n",
    "\n",
    "example:\n",
    "```python\n",
    "dogs[\"height_cm\"].mean()\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "(b). Summarizing dates\n",
    "- Oldest dog:\n",
    "```python\n",
    "dogs[\"date_of_birth\"].min()\n",
    "```\n",
    "\n",
    "- Youngest dog:\n",
    "```python\n",
    "dogs[\"date_of_birth\"].max()\n",
    "```\n",
    "\n",
    "(c). the .agg() method\n",
    "- .agg() method allows you to apply multiple functions to a DataFrame or Series.\n",
    "- You can pass a list of functions to .agg() to apply them to the DataFrame or Series.\n",
    "\n",
    "example 1 : percentile determination of a certain column\n",
    "```python\n",
    "def pct30(column):\n",
    "return column.quantile(0.3)\n",
    "\n",
    "dogs[\"weight_kg\"].agg(pct30) #22.599999999999998\n",
    "```\n",
    "\n",
    "example 2: Summaries on multiple columns\n",
    "```python\n",
    "dogs[[\"weight_kg\", \"height_cm\"]].agg(pct30)\n",
    "```\n",
    "output 2: \n",
    "```\n",
    "weight_kg 22.6\n",
    "height_cm 45.4\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "example 3: multiple summaries\n",
    "```python\n",
    "def pct40(column):\n",
    "return column.quantile(0.4)\n",
    "dogs[\"weight_kg\"].agg([pct30, pct40])\n",
    "```\n",
    "output 3:\n",
    "```\n",
    "pct30 22.6\n",
    "pct40 24.0\n",
    "Name: weight_kg, dtype: float64\n",
    "```\n",
    "\n",
    "(d). commutative \n",
    "[![https://imgur.com/SIuU5kQ.png](https://imgur.com/SIuU5kQ.png)](https://imgur.com/SIuU5kQ.png)\n",
    "\n",
    "\n",
    "(e). Commutative statistics\n",
    "- .cummax()\n",
    "- .cummin()\n",
    "- .cumprod()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. (Practice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- mean and median\n",
    "\n",
    "Summary statistics are exactly what they sound like - they summarize many numbers in one statistic. For example, mean, median, minimum, maximum, and standard deviation are summary statistics. Calculating summary statistics allows you to get a better sense of your data, even if there's a lot of it.\n",
    "\n",
    "sales is available and pandas is loaded as pd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  store type  department        date  weekly_sales  is_holiday  \\\n",
      "0           0      1    A           1  2010-02-05      24924.50       False   \n",
      "1           1      1    A           1  2010-03-05      21827.90       False   \n",
      "2           2      1    A           1  2010-04-02      57258.43       False   \n",
      "3           3      1    A           1  2010-05-07      17413.94       False   \n",
      "4           4      1    A           1  2010-06-04      17558.09       False   \n",
      "\n",
      "   temperature_c  fuel_price_usd_per_l  unemployment  \n",
      "0       5.727778              0.679451         8.106  \n",
      "1       8.055556              0.693452         8.106  \n",
      "2      16.816667              0.718284         7.808  \n",
      "3      22.527778              0.748928         7.808  \n",
      "4      27.050000              0.714586         7.808  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10774 entries, 0 to 10773\n",
      "Data columns (total 10 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Unnamed: 0            10774 non-null  int64  \n",
      " 1   store                 10774 non-null  int64  \n",
      " 2   type                  10774 non-null  object \n",
      " 3   department            10774 non-null  int64  \n",
      " 4   date                  10774 non-null  object \n",
      " 5   weekly_sales          10774 non-null  float64\n",
      " 6   is_holiday            10774 non-null  bool   \n",
      " 7   temperature_c         10774 non-null  float64\n",
      " 8   fuel_price_usd_per_l  10774 non-null  float64\n",
      " 9   unemployment          10774 non-null  float64\n",
      "dtypes: bool(1), float64(4), int64(3), object(2)\n",
      "memory usage: 768.2+ KB\n",
      "None\n",
      "23843.95014850566\n",
      "12049.064999999999\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "sales = pd.read_csv('./data/sales_subset.csv')\n",
    "\n",
    "# Print the head of the sales DataFrame\n",
    "print(sales.head())\n",
    "\n",
    "# Print the info about the sales DataFrame\n",
    "print(sales.info())\n",
    "\n",
    "# # Print the mean of weekly_sales\n",
    "print(sales['weekly_sales'].mean())\n",
    "\n",
    "# # Print the median of weekly_sales\n",
    "print(sales['weekly_sales'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Summarizing dates\n",
    "\n",
    "Summary statistics can also be calculated on date columns that have values with the data type datetime64. Some summary statistics — like mean — don't make a ton of sense on dates, but others are super helpful, for example, minimum and maximum, which allow you to see what time range your data covers.\n",
    "\n",
    "sales is available and pandas is loaded as pd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012-10-26\n",
      "2010-02-05\n"
     ]
    }
   ],
   "source": [
    "# Print the maximum of the date column\n",
    "print(sales['date'].max())\n",
    "\n",
    "# Print the minimum of the date column\n",
    "print(sales['date'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cumulative statistics\n",
    "Cumulative statistics can also be helpful in tracking summary statistics over time. In this exercise, you'll calculate the cumulative sum and cumulative max of a department's weekly sales, which will allow you to identify what the total sales were so far as well as what the highest weekly sales were so far.\n",
    "\n",
    "A DataFrame called sales_1_1 has been created for you, which contains the sales data for department 1 of store 1. pandas is loaded as pd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date  weekly_sales  cum_weekly_sales  cum_max_sales\n",
      "0  2010-02-05      24924.50          24924.50       24924.50\n",
      "1  2010-03-05      21827.90          46752.40       24924.50\n",
      "2  2010-04-02      57258.43         104010.83       57258.43\n",
      "3  2010-05-07      17413.94         121424.77       57258.43\n",
      "4  2010-06-04      17558.09         138982.86       57258.43\n"
     ]
    }
   ],
   "source": [
    "sales_1_1 = sales.head()\n",
    "# Sort sales_1_1 by date\n",
    "sales_1_1 = sales_1_1.sort_values('date', ascending=True)\n",
    "# Get the cumulative sum of weekly_sales, add as cum_weekly_sales col\n",
    "sales_1_1['cum_weekly_sales'] = sales_1_1['weekly_sales'].cumsum()\n",
    "sales_1_1\n",
    "\n",
    "\n",
    "# # Get the cumulative max of weekly_sales, add as cum_max_sales col\n",
    "sales_1_1['cum_max_sales'] = sales_1_1['weekly_sales'].cummax()\n",
    "\n",
    "# # See the columns you calculated\n",
    "print(sales_1_1[[\"date\", \"weekly_sales\", \"cum_weekly_sales\", \"cum_max_sales\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Counting\n",
    "### (Theory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Dropping duplicate names\n",
    "```python\n",
    " vet_visits.drop_duplicates(subset=\"name\")\n",
    "```\n",
    "![{BBF1423B-AAD6-46D4-BC39-B906F995FE8D}.png](./images/{BBF1423B-AAD6-46D4-BC39-B906F995FE8D}.png)\n",
    "\n",
    "2. dropping duplicate pairs\n",
    "```python\n",
    " unique_dogs = vet_visits.drop_duplicates(subset=[\"name\", \"breed\"]) \n",
    "print(unique_dogs)\n",
    "```\n",
    "![image.png](./images/image.png)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
